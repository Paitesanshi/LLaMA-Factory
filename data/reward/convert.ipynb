{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_path=\"/home/v-leiwang8/sft/LLaMA-Factory/data/reward/reward_text.json\"\n",
    "with open(file_path,'r',encoding='utf-8') as f:\n",
    "    data=json.load(f)\n",
    "\n",
    "critic=\"\"\"\n",
    "<Note>:\n",
    "Please identify any issues based on these aspects:\n",
    "1. Factual Accuracy: Identify and point out any elements that do not accurately match the historical or factual backdrop.\n",
    "2. Character Consistency: Explicitly highlight inconsistencies between the character's actions, dialogues, and their predefined traits and goals.\n",
    "3. Logical Coherence: Point out any logical fallacies or actions that contradict the established context or character logic.\n",
    "4. Content Redundancy: Identify repetitions in dialogue or action that could detract from engagement and realism.\n",
    "5. Emotional Expression: Assess whether emotional responses and expressions are appropriate and convincingly portrayed, highlighting any discrepancies.\n",
    "6. Interaction Adaptability: Critique the character's interactions with others, noting any unnatural or contextually inappropriate responses.\n",
    "7. Creativity and Originality: Evaluate the creativity of responses and actions, pointing out generic or unoriginal content.\n",
    "8. Detail Handling: Scrutinize the level of detail in scene setting and character enactment, marking areas lacking depth or accuracy.\n",
    "9. Style Consistency: Ensure that the narrative and linguistic style remains consistent, identifying any deviations.\n",
    "10. Fluency and Quality: Critically assess the smoothness and quality of the text, highlighting any grammatical errors or awkward phrasings.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "for i in range(0, len(data)):\n",
    "   # batch_prompts = data[i:i+batch_size]['instruction']\n",
    "    \n",
    "    original_string=data[i]['instruction']\n",
    "    index = original_string.find(\"<Criteria>:\")\n",
    "\n",
    "    # 在 \"<Score>:\" 之前插入新的字符串\n",
    "    modified_string = original_string[:index] + critic + original_string[index:]\n",
    "\n",
    "    #prompt=data[j]['instruction']+critic\n",
    "    data[i]['instruction']=modified_string\n",
    "\n",
    "with open(\"reward_text_critic.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "with open(\"evaluation_critic_short_new.json\") as f:\n",
    "    data=json.load(f)\n",
    "    # sample 2000 data for training and others for testing\n",
    "    for i in range(0, len(data)):\n",
    "       data[i]['id']=i\n",
    "    random.shuffle(data)\n",
    "    train=data[:2000]\n",
    "    test=data[2000:]\n",
    "\n",
    "    with open(\"evaluation_critic_short_new_train.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(train, f, ensure_ascii=False, indent=4)\n",
    "    with open(\"evaluation_critic_short_new_test.json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(test, f, ensure_ascii=False, indent=4)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
